# Introduction

I am currently a PhD candidate at the University of Sydney. My research focus on statistics and bioinformatics and I have an active interest in `R` and `tidyverse`. Since May 2019, I have been undertaking the [tidytuesday](https://github.com/rfordatascience/tidytuesday) challenges. 

Due to my very limited time and unlimited amount of curiosity, I have decided to not produce a detailed annotated R Markdown report for every data challenge. Instead, I will post my most important findings in each data challenge below. In addition, I will also put up some brief comments about the packages that I have encountered along the way (e.g. ease of use, maturity of the package). 

This webpage was deployed through [Travis](https://travis-ci.org/kevinwang09/tidytuesday) and GitHub Pages.

# Why am I doing this?

The main reasons that I am doing this challenge: 
  
  1. Create a repository of code snippets. Due to the ethics restriction associated with my research, I cannot always share codes from my own research but I can always apply the same code to different data. 
  2. Learn efficient coding and reporting. I typically only set aside a few hours a week to complete these challenges due to my busy schedule. I want to make sure that I can code in a reproducible way and have something meaningful every week. 
  3. Building up a data repository for teaching. I also teach at the University of Sydney as a casual lecturer. I have to design assignments and tutorial examples every now and then. Having access to a repository of data that I understand and work on is very helpful for my own teaching. 
  4. Learn more about new packages and technologies. I consider myself to be quite experienced at `tidyverse` and most mainstream machine learning packages. But with so new packages released everyday, it is hard for me to understand what these packages bring to the R community without trying them out. I aim to use at least one new package or an alternative way to do a task in every data challenge. 